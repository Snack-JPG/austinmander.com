# Draft Posts — Batch 002

Ready for review. Edit freely before posting.

---

## Post 6: Claude Code Isn't Just for Developers

**Topic:** Claude Code for non-technical users

**Hook:** Challenges the assumption, opens doors for broader audience

```
Claude Code isn't a coding tool.

It's a general-purpose AI agent that happens to live in the terminal.

I know — "terminal" sounds scary if you're not technical.
But here's the thing: you only need to know 3 commands.

What non-developers are actually using it for:

→ Organising messy file systems
   "Find duplicate files and help me decide which to keep"

→ Processing large documents
   Upload 500 pages. Ask questions. Get answers.
   No file size limits like the web version.

→ Summarising call transcripts
   Drop in recordings. Get structured notes.

→ Research that actually remembers context
   Long-running sessions that don't forget what you discussed.

The trick: stop thinking of it as "Claude Code."
Think of it as "Claude with superpowers."

It runs locally. It can access your files.
It doesn't time out after 10 minutes.

If you've ever hit the limits of ChatGPT or Claude's web app,
this is the unlock.

The barrier isn't technical skill.
It's just knowing it exists.
```

**Notes:** Directly addresses the "it's for devs" misconception. Practical examples. Empowering tone without being condescending.

---

## Post 7: What I'm Building (Change Radar)

**Topic:** Build in public — introducing Change Radar

**Hook:** Shows real work, not just commentary

```
Building an AI product is mostly debugging why the AI did something weird.

I'm working on Change Radar — a tool that helps organisations
track what's actually happening in their transformation programs.

The problem it solves:

Leaders spend hours every week compiling status updates.
Reading reports. Chasing people for information.
By the time they spot a risk, it's already a crisis.

What Change Radar does:

→ Connects to existing tools (Jira, Monday, Slack, etc.)
→ AI reads the actual data — not just summaries
→ Flags risks before they're obvious
→ Generates the executive summary automatically

The goal: leaders get their time back,
and problems get caught earlier.

Currently in development. Testing with early users soon.

I'll share more as I build — what works, what doesn't,
and what I'm learning about shipping AI products.

If you're leading transformation programs and drowning in updates,
I'd love to hear what's eating your time.
```

**Notes:** Introduces the product naturally. Focuses on problem solved. Invites engagement from target audience.

---

## Post 8: Why Most AI Projects Fail

**Topic:** Honest take on AI implementation failures

**Hook:** Contrarian but grounded, useful insight

```
Most AI projects fail for the same reason:

They start with "we should use AI"
instead of "we have a problem."

The pattern I keep seeing:

1. Company gets excited about AI
2. Starts a vague "AI initiative"
3. Builds something cool in a demo
4. Can't figure out where it fits in real workflows
5. Project quietly dies

The fix is boring:

Start with a specific, painful problem.
Something that wastes time every week.
Something with clear before/after.

Then ask: can AI actually help here?

Sometimes yes. Sometimes a simple script is enough.
Sometimes the problem is people, not technology.

The companies getting real value from AI
aren't the ones with the biggest budgets.

They're the ones who started with one workflow,
automated it properly, and expanded from there.

Focus beats ambition.
```

**Notes:** Honest, not preachy. Actionable insight. Positions you as someone who's seen what works and what doesn't.

---

## Post 9: AI Agents Explained Simply

**Topic:** Demystifying agentic AI

**Hook:** Makes complex concept accessible

```
Everyone's talking about AI agents.
Here's what that actually means.

Regular AI:
You ask a question → AI gives an answer → Done.

AI agents:
You give a goal → AI figures out the steps →
Takes actions → Checks if it worked → Adjusts.

Simple example:

Regular AI: "Here are some flights to Paris."
AI agent: Books the flight, adds it to your calendar,
         emails your team, updates your expense tracker.

The difference is autonomy.

Agents don't just respond. They act.
They break problems into steps.
They use tools. They loop until the job is done.

Why this matters:

Most AI today is reactive. You prompt, it responds.
Agents are proactive. You set a goal, they figure it out.

We're still early. Most "agents" are demos.
But the direction is clear:

AI that does things, not just AI that says things.

That's the shift to watch.
```

**Notes:** Clear progression from simple to complex. Concrete example. Honest about current state ("most are demos").

---

## Post 10: The Real Value of AI Subscriptions

**Topic:** Practical breakdown of AI tool costs vs value

**Hook:** Useful, concrete, helps people make decisions

```
I pay for Claude Pro, ChatGPT Plus, and a few other AI tools.

People ask: is it worth it?

Here's how I think about it:

Claude Pro (£18/month):
→ I use it 2-3 hours daily for real work
→ Document processing, writing, analysis
→ Replaces tasks that would take 2-3x longer manually
→ Easy yes.

ChatGPT Plus (£20/month):
→ Voice mode when I'm walking
→ Quick questions, exploration
→ Could probably cancel, but the convenience is worth it.

Claude Code (usage-based):
→ This is where the real leverage is
→ Complex tasks that would take hours
→ Costs more, but the ROI is obvious when you need it.

The question isn't "is AI expensive?"

It's "what would I pay someone to do this work?"

If an AI tool saves me 5 hours a month,
that's worth way more than £20.

The mistake: subscribing to everything "just in case."
The fix: use one tool seriously for a month. Measure the value.
Then decide.

What's actually earning its subscription in your stack?
```

**Notes:** Specific, honest about own spending. Practical framework. Engagement question at end.

**⚠️ Before posting:** Verify the subscription prices match what you actually pay. Update with your real numbers.

---

## Review Checklist

Before posting, verify each post:

- [ ] Follows voice guide (humble, informative, honest)
- [ ] Has one clear insight
- [ ] No hype language ("revolutionary", "game-changing")
- [ ] Would be useful to someone who never hires you
- [ ] You'd be comfortable if a technical person read it
- [ ] Ends with engagement hook or clear takeaway

---

## Suggested Posting Order (Combined with Batch 001)

**Week 1:**
- Day 1: Post 3 (Your automation) — establishes builder credibility
- Day 3: Post 6 (Claude Code for non-devs) — valuable, shareable
- Day 5: Post 5 (Learning curves) — thoughtful, discussion-worthy

**Week 2:**
- Day 1: Post 1 (Claude creates documents) — practical tip
- Day 3: Post 8 (Why AI projects fail) — contrarian, insightful
- Day 5: Post 9 (AI agents explained) — educational

**Week 3:**
- Day 1: Post 7 (Change Radar intro) — build in public
- Day 3: Post 4 (MCPs explained) — educational
- Day 5: Post 10 (AI subscription value) — practical

**Week 4:**
- Day 1: Post 2 (Claude vs ChatGPT) — opinion, drives comments
- Day 3-5: New content based on what resonated

---

*Drafted: December 2024*
